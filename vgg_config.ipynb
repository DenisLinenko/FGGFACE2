{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from os import listdir\n",
    "from os.path import isdir\n",
    "from numpy import savez_compressed\n",
    "from matplotlib import pyplot\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from scipy.spatial.distance import cosine\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from numpy import load\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras_vggface.utils import preprocess_input\n",
    "from time import perf_counter\n",
    "import sys\n",
    "import numpy as np\n",
    "import io\n",
    "import json\n",
    "import math\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import tensorflow as tf\n",
    "from numpy import expand_dims\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import SVC\n",
    "from scipy.spatial import distance\n",
    "import scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file():\n",
    "    file = open(\"test_data.txt\", \"r\")\n",
    "    contents = file.read()\n",
    "    dictionary = ast.literal_eval(contents)\n",
    "    file.close()\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_images_matching_criteria(dictionary1, criteria):\n",
    "    known_image = ''\n",
    "    test_image = ''\n",
    "    for key, value in dictionary1.items():\n",
    "        if(key == criteria):\n",
    "            known_image = value[0]\n",
    "            test_image = value[1]\n",
    "    known_image_path = 'known/'+known_image+'.jpg' \n",
    "    test_image_path = 'test/'+test_image+'.jpg'\n",
    "    return known_image_path, test_image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# extract a single face from a given photograph\n",
    "def extract_face(filename, required_size=(224, 224)):\n",
    "\t# load image from file\n",
    "\tpixels = pyplot.imread(filename)\n",
    "\t# create the detector, using default weights\n",
    "\tdetector = MTCNN()\n",
    "\t# detect faces in the image\n",
    "\tresults = detector.detect_faces(pixels)\n",
    "\n",
    "\tprint(len(results), 'faces have been found')\n",
    "\n",
    "\t#--------------------------- detecting the number of faces ------------------------------------\n",
    "\tif len(results) == 0:\n",
    "\t\traise Exception('No faces detected')\n",
    "\telif len(results) > 1:\n",
    "\t\traise Exception('Multiple faces detected')\t\t\n",
    "\n",
    "\t# extract the bounding box from the first face\n",
    "\tx1, y1, width, height = results[0]['box']\n",
    "\tx2, y2 = x1 + width, y1 + height\n",
    "\t# extract the face\n",
    "\tface = pixels[y1:y2, x1:x2]\n",
    "\t# resize pixels to the model size\n",
    "\timage = Image.fromarray(face)\n",
    "\timage = image.resize(required_size)\n",
    "\tface_array = asarray(image)\n",
    "    \n",
    "\treturn face_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(filenames):\n",
    "    print(\"filenames------>\", filenames)\n",
    "    # extract faces\n",
    "    faces = [extract_face(f) for f in filenames]\n",
    "    # convert into an array of samples\n",
    "    samples = asarray(faces, 'float32')\n",
    "    # prepare the face for the model, e.g. center pixels\n",
    "    samples = preprocess_input(samples, version=2)\n",
    "    # create predication model - note that we have several \n",
    "    model = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')\n",
    "    # perform prediction\n",
    "    yhat = model.predict(samples)\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_initial_images(path_known, path_test):\n",
    "    \n",
    "    rcParams['figure.figsize'] = 13 ,10\n",
    "    img_A = mpimg.imread(path_known)\n",
    "    img_B = mpimg.imread(path_test)\n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    ax[0].imshow(img_A);\n",
    "    ax[1].imshow(img_B);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_match(known_embedding, candidate_embedding, thresh=0.5):\n",
    "\t# calculate distance between embeddings\n",
    "\tscore = cosine(known_embedding, candidate_embedding)\n",
    "\tif score <= thresh:\t\n",
    "\t\tprint('>face is a Match (%.3f <= %.3f) = %.0f' % (score, thresh, math.floor((1-score)*100)), \"%\")\n",
    "\telse:\n",
    "\t\tprint('>face is NOT a Match (%.3f <= %.3f) = %.0f' % (score, thresh, math.floor((1-score)*100)), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(image1, image2):\n",
    "    print(\"-------images------\", image1, image2)\n",
    "    \n",
    "    vector1 = get_embeddings([image1])[0]\n",
    "    \n",
    "    vector2 = get_embeddings([image2])[0]\n",
    "    \n",
    "\n",
    "    is_match(vector1, vector2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
